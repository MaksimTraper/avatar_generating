{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install datasets\\n!pip install transformers[torch] accelerate -U\\npip install pyttsx3\\n!apt-get update\\n!apt-get install -y espeak libespeak1\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install datasets\n",
    "!pip install transformers[torch] accelerate -U\n",
    "pip install pyttsx3\n",
    "!apt-get update\n",
    "!apt-get install -y espeak libespeak1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJOv4I6T1w4_",
    "outputId": "1671ea11-6f1b-4a57-e4c9-5e39d27ccf61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.5212835073471069}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Загрузка токенизатора и модели DistilRuBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "\n",
    "# Создание пайплайна для анализа текста\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Пример текста на русском языке\n",
    "text = \"Я очень счастлив сегодня!\"\n",
    "\n",
    "# Анализ текста\n",
    "result = nlp(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fhRz1oUH29Vn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport requests\\nimport zipfile\\nimport io\\nimport numpy as np\\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\\nfrom datasets import Dataset\\n\\n# Скачиваем и распаковываем датасет RuSentiment\\nurl = \"https://github.com/strawberrypie/rusentiment/archive/refs/heads/master.zip\"\\nr = requests.get(url)\\nz = zipfile.ZipFile(io.BytesIO(r.content))\\nz.extractall()\\n\\n# Чтение данных\\ndf = pd.read_csv(\"rusentiment-master/Dataset/rusentiment_preselected_posts.csv\")\\n\\n# Преобразование меток тональности в числовые значения\\nlabel_map = {\"neutral\": 0, \"positive\": 1, \"negative\": 2}\\ndf[\\'label\\'] = df[\\'label\\'].map(label_map)\\n\\n# Удаление строк с пустыми и недопустимыми значениями\\ndf = df.dropna(subset=[\\'text\\', \\'label\\'])\\ndf = df[df[\\'label\\'].notna()]\\ndf = df[df[\\'label\\'] != \\'inf\\']\\ndf = df[df[\\'label\\'] != \\'-inf\\']\\n\\n# Преобразование меток в целые числа\\ndf[\\'label\\'] = df[\\'label\\'].astype(int)\\n\\n# Удаление строк с пустыми значениями\\ndf = df.dropna(subset=[\\'text\\', \\'label\\'])\\n\\n# Конвертация данных в формат, подходящий для обучения\\ntrain_dataset = Dataset.from_pandas(df[[\\'text\\', \\'label\\']])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import Dataset\n",
    "\n",
    "# Скачиваем и распаковываем датасет RuSentiment\n",
    "url = \"https://github.com/strawberrypie/rusentiment/archive/refs/heads/master.zip\"\n",
    "r = requests.get(url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()\n",
    "\n",
    "# Чтение данных\n",
    "df = pd.read_csv(\"rusentiment-master/Dataset/rusentiment_preselected_posts.csv\")\n",
    "\n",
    "# Преобразование меток тональности в числовые значения\n",
    "label_map = {\"neutral\": 0, \"positive\": 1, \"negative\": 2}\n",
    "df['label'] = df['label'].map(label_map)\n",
    "\n",
    "# Удаление строк с пустыми и недопустимыми значениями\n",
    "df = df.dropna(subset=['text', 'label'])\n",
    "df = df[df['label'].notna()]\n",
    "df = df[df['label'] != 'inf']\n",
    "df = df[df['label'] != '-inf']\n",
    "\n",
    "# Преобразование меток в целые числа\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Удаление строк с пустыми значениями\n",
    "df = df.dropna(subset=['text', 'label'])\n",
    "\n",
    "# Конвертация данных в формат, подходящий для обучения\n",
    "train_dataset = Dataset.from_pandas(df[['text', 'label']])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9581083cabd64fa7b61e65e4e49f5098",
      "79db326166db46a09ff85dc8a2a432a8",
      "73fab7e20aa240f1b0e42d3661df5734",
      "d5213b68296f440bb0d06b645631c24a",
      "8430ce4307064df0b4c72b4f41c8c5ab",
      "fb8aacd4797b4df79e17ab2953a7ebcc",
      "992c01ff6726432181a0ee0c6093e8f3",
      "24cab206b88d444e92da0b4ce5b486be",
      "76f7ce8e599a468a8ee0d887f0ae15b4",
      "2c30de3648bd484cbadf444250eae7be",
      "05c710f759a244ba9b19fec4d6911632",
      "1585232a2cc0468bab6c25dd732d000c",
      "9b0bfd95befd4009800fdc0718e227db",
      "a4568efecb054f1aa6bbd62e8ed4471f",
      "86bde030395f447199944095d4149b16",
      "5e3ced642e764c78b3e5edb3757598ed",
      "690650a936a14fdba144151a1dcb9df7",
      "9e66884d200d49fabaf365b06cf3150e",
      "3b8f0d689130419ea4e4e8c726e7433a",
      "19b87590c4e94419b2cdca4aa6dd0dbd",
      "df24c9bbf25a47549691fdfb0907ac5e",
      "d9571c9f10d3425f9681dc657ea82273"
     ]
    },
    "id": "Mc-KXOxs14af",
    "outputId": "1806f190-c352-4e36-d287-6c68653dd4ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\\nimport torch\\n\\n# Загрузка токенизатора и модели DistilRuBERT\\ntokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\\nmodel = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny2\", num_labels=3)\\n\\n# Токенизация данных\\ndef tokenize_function(examples):\\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\\n\\ntokenized_datasets = train_dataset.map(tokenize_function, batched=True)\\nprint(tokenized_datasets)\\n\\n# Проверка формата токенизированных данных\\nprint(tokenized_datasets.features)\\ndef format_labels(examples):\\n    examples[\\'label\\'] = [int(label) for label in examples[\\'label\\']]\\n    return examples\\n\\ntokenized_datasets = tokenized_datasets.map(format_labels, batched=True)\\n\\n# Настройки обучения\\ntraining_args = TrainingArguments(\\n    output_dir=\\'./results\\',\\n    num_train_epochs=3,\\n    per_device_train_batch_size=4,\\n    per_device_eval_batch_size=4,   # Уменьшенный размер батча\\n    gradient_accumulation_steps=4,\\n    warmup_steps=500,\\n    weight_decay=0.01,\\n    logging_dir=\\'./logs\\',\\n    logging_steps=10,\\n)\\n\\ndef compute_metrics(p):\\n    preds = np.argmax(p.predictions, axis=1)\\n    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average=\\'weighted\\')\\n    acc = accuracy_score(p.label_ids, preds)\\n    return {\\n        \\'accuracy\\': acc,\\n        \\'f1\\': f1,\\n        \\'precision\\': precision,\\n        \\'recall\\': recall\\n    }\\n\\n# Создание тренера\\ntrainer = Trainer(\\n    model=model,\\n    args=training_args,\\n    train_dataset=tokenized_datasets,\\n    compute_metrics=compute_metrics\\n)\\n\\n# Обучение модели\\ntrainer.train()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Загрузка токенизатора и модели DistilRuBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny2\", num_labels=3)\n",
    "\n",
    "# Токенизация данных\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = train_dataset.map(tokenize_function, batched=True)\n",
    "print(tokenized_datasets)\n",
    "\n",
    "# Проверка формата токенизированных данных\n",
    "print(tokenized_datasets.features)\n",
    "def format_labels(examples):\n",
    "    examples['label'] = [int(label) for label in examples['label']]\n",
    "    return examples\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(format_labels, batched=True)\n",
    "\n",
    "# Настройки обучения\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,   # Уменьшенный размер батча\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Создание тренера\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "trainer.train()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vV4tP5XFLWPu"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "output_dir = './bert_fine_tuned_model'\n",
    "\n",
    "'''\n",
    "# Сохранение модели\n",
    "model.save_pretrained(output_dir)\n",
    "\n",
    "# Сохранение токенизатора\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {output_dir}\")\n",
    "'''\n",
    "# Загрузка сохраненной модели и токенизатора\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "_FsZUsduMApI",
    "outputId": "3747d137-4f52-44e9-b502-e5b735f08028"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport shutil\\nfrom google.colab import files\\n\\n# Путь к сохраненной модели и токенизатору\\noutput_dir = './fine_tuned_model'\\n\\n# Создание архива\\nshutil.make_archive('fine_tuned_model', 'zip', output_dir)\\n\\n# Загрузка архива на локальный компьютер\\nfiles.download('fine_tuned_model.zip')\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Путь к сохраненной модели и токенизатору\n",
    "output_dir = './fine_tuned_model'\n",
    "\n",
    "# Создание архива\n",
    "shutil.make_archive('fine_tuned_model', 'zip', output_dir)\n",
    "\n",
    "# Загрузка архива на локальный компьютер\n",
    "files.download('fine_tuned_model.zip')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jzmUwlpMJLJ",
    "outputId": "1c576af0-6c78-4b13-c9c1-d4934f7a8ac0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'positive', 'score': 0.9574131369590759}]\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Словарь для интерпретации меток\n",
    "label_map = {0: \"neutral\", 1: \"positive\", 2: \"negative\"}\n",
    "\n",
    "# Пример текста на русском языке\n",
    "text = \"Я очень счастлив сегодня!\"\n",
    "\n",
    "# Анализ текста\n",
    "result = nlp(text)\n",
    "\n",
    "# Интерпретация результата\n",
    "def Interpritate_result(result):\n",
    "  for r in result:\n",
    "      r['label'] = label_map[int(r['label'].split('_')[-1])]  # Преобразование метки в читаемый формат\n",
    "\n",
    "Interpritate_result(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXPF3ljONWRe",
    "outputId": "c3d000fc-e0bd-4eed-9af6-663a059ddd75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'positive', 'score': 0.8959010243415833}]\n"
     ]
    }
   ],
   "source": [
    "result = nlp('Слушай, это было круто.')\n",
    "Interpritate_result(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NscOhbxdQHYM"
   },
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "from random import *\n",
    "\n",
    "def analyze_emotion(text):\n",
    "    result = nlp(text)\n",
    "    for r in result:\n",
    "        numerical_label = int(r['label'].split('_')[-1])\n",
    "        r['label'] = label_map[numerical_label]\n",
    "    return result[0]['label'], result[0]['score']\n",
    "\n",
    "def generate_audio(text, emotion):\n",
    "    engine = pyttsx3.init()\n",
    "\n",
    "    voices = engine.getProperty('voices')\n",
    "\n",
    "    # Задать голос по умолчанию\n",
    "    engine.setProperty('voice', 'ru')\n",
    "\n",
    "    # Попробовать установить предпочтительный голос\n",
    "    for voice in voices:\n",
    "        if voice.name == 'Vsevolod':\n",
    "            engine.setProperty('voice', voice.id)\n",
    "\n",
    "    # Настройка параметров голоса в зависимости от эмоции\n",
    "    if emotion == \"positive\":\n",
    "        engine.setProperty('rate', 150)  # Скорость речи\n",
    "        engine.setProperty('volume', 1.0)  # Громкость речи\n",
    "    elif emotion == \"negative\":\n",
    "        engine.setProperty('rate', 100)  # Скорость речи\n",
    "        engine.setProperty('volume', 0.7)  # Громкость речи\n",
    "    else:  # neutral\n",
    "        engine.setProperty('rate', 120)  # Скорость речи\n",
    "        engine.setProperty('volume', 0.9)  # Громкость речи\n",
    "    \n",
    "    output_path = f\"output_{emotion}_{randint(0,10000)}.mp3\"\n",
    "    engine.save_to_file(text, output_path)\n",
    "    engine.runAndWait()\n",
    "\n",
    "    return output_path\n",
    "\n",
    "def process_text_and_generate_audio(text):\n",
    "    # Анализ текста на эмоции\n",
    "    emotion, score = analyze_emotion(text)\n",
    "    print(f\"Emotion: {emotion}, Score: {score}\")\n",
    "\n",
    "    # Генерация аудиофайла на основе эмоции\n",
    "    audio_file = generate_audio(text, emotion)\n",
    "    print(f\"Audio file generated: {audio_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_text_by_mood(text):\n",
    "    # Пример простого деления по предложениям\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_parts(parts):\n",
    "    emotions = []\n",
    "    for part in parts:\n",
    "        emotion, score = analyze_emotion(part)\n",
    "        emotions.append((part, emotion))\n",
    "    return emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_audio_parts(parts_with_emotions):\n",
    "    audio_files = []\n",
    "    for i, (text, emotion) in enumerate(parts_with_emotions):\n",
    "        audio_file = generate_audio(text, emotion)\n",
    "        if os.path.exists(audio_file):\n",
    "            print(f\"Audio file generated: {audio_file}\")\n",
    "        else:\n",
    "            print(f\"Error: Audio file not generated: {audio_file}\")\n",
    "        audio_files.append(audio_file)\n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_sadtalker(src_image, audio_file, output_file):\n",
    "    command = [\n",
    "        'python', 'inference.py',\n",
    "        '--driven_audio', audio_file,\n",
    "        '--source_image', src_image,\n",
    "        '--result_dir', output_file\n",
    "    ]\n",
    "    subprocess.run(command)\n",
    "\n",
    "def generate_video_parts(audio_files, parts_with_emotions):\n",
    "    video_files = []\n",
    "    src_image = \"man.png\"  # Изображение вашего аватара\n",
    "    %cd ./../SadTalker\n",
    "    for i, (audio_file, (text, emotion)) in enumerate(zip(audio_files, parts_with_emotions)):\n",
    "        output_file = f\"output_video_part_{i}\"\n",
    "        run_sadtalker(src_image, audio_file, f'./../DLS_project/result/{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}/{output_file}')\n",
    "        output_video_path = os.path.join(output_file, 'result.mp4')\n",
    "        if os.path.exists(output_video_path):\n",
    "            print(f\"Video file generated: {output_video_path}\")\n",
    "        else:\n",
    "            print(f\"Error: Video file not generated: {output_video_path}\")\n",
    "        video_files.append(output_video_path)\n",
    "    %cd ./../DLS_project\n",
    "    return video_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import concatenate_videoclips, VideoFileClip\n",
    "\n",
    "def combine_videos(video_files):\n",
    "    clips = [VideoFileClip(video) for video in video_files]\n",
    "    final_clip = concatenate_videoclips(clips)\n",
    "    final_clip.write_videofile(\"final_output_video.mp4\", codec=\"libx264\")\n",
    "    if os.path.exists(\"final_output_video.mp4\"):\n",
    "        print(\"Final video generated successfully: final_output_video.mp4\")\n",
    "    else:\n",
    "        print(\"Error: Final video not generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_avatar(text):\n",
    "    parts = split_text_by_mood(text)\n",
    "    print(parts)\n",
    "    \n",
    "    parts_with_emotions = analyze_parts(parts)\n",
    "    print(parts_with_emotions)\n",
    "    \n",
    "    audio_files = generate_audio_parts(parts_with_emotions)\n",
    "    print(audio_files)\n",
    "    \n",
    "    video_files = generate_video_parts(audio_files, parts_with_emotions)\n",
    "    print(video_files)\n",
    "    \n",
    "    combine_videos(video_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Я очень счастлив сегодня!', 'Но вчера мне было грустно.', 'Завтра будет новый день, и я надеюсь, что он будет лучше.']\n",
      "[('Я очень счастлив сегодня!', 'positive'), ('Но вчера мне было грустно.', 'negative'), ('Завтра будет новый день, и я надеюсь, что он будет лучше.', 'positive')]\n",
      "Audio file generated: output_positive_5843.mp3\n",
      "Audio file generated: output_negative_1933.mp3\n",
      "Audio file generated: output_positive_7145.mp3\n",
      "['output_positive_5843.mp3', 'output_negative_1933.mp3', 'output_positive_7145.mp3']\n",
      "D:\\SadTalker\n",
      "Error: Video file not generated: output_video_part_0\\result.mp4\n",
      "Error: Video file not generated: output_video_part_1\\result.mp4\n",
      "Error: Video file not generated: output_video_part_2\\result.mp4\n",
      "D:\\DLS_project\n",
      "['output_video_part_0\\\\result.mp4', 'output_video_part_1\\\\result.mp4', 'output_video_part_2\\\\result.mp4']\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "MoviePy error: the file output_video_part_0\\result.mp4 could not be found!\nPlease check that you entered the correct path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Пример использования\u001b[39;00m\n\u001b[0;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЯ очень счастлив сегодня! Но вчера мне было грустно. Завтра будет новый день, и я надеюсь, что он будет лучше.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mMake_avatar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m, in \u001b[0;36mMake_avatar\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     11\u001b[0m video_files \u001b[38;5;241m=\u001b[39m generate_video_parts(audio_files, parts_with_emotions)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(video_files)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mcombine_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m, in \u001b[0;36mcombine_videos\u001b[1;34m(video_files)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_videos\u001b[39m(video_files):\n\u001b[1;32m----> 4\u001b[0m     clips \u001b[38;5;241m=\u001b[39m [VideoFileClip(video) \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m video_files]\n\u001b[0;32m      5\u001b[0m     final_clip \u001b[38;5;241m=\u001b[39m concatenate_videoclips(clips)\n\u001b[0;32m      6\u001b[0m     final_clip\u001b[38;5;241m.\u001b[39mwrite_videofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_output_video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibx264\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_videos\u001b[39m(video_files):\n\u001b[1;32m----> 4\u001b[0m     clips \u001b[38;5;241m=\u001b[39m [\u001b[43mVideoFileClip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m video_files]\n\u001b[0;32m      5\u001b[0m     final_clip \u001b[38;5;241m=\u001b[39m concatenate_videoclips(clips)\n\u001b[0;32m      6\u001b[0m     final_clip\u001b[38;5;241m.\u001b[39mwrite_videofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_output_video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibx264\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py:88\u001b[0m, in \u001b[0;36mVideoFileClip.__init__\u001b[1;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Make a reader\u001b[39;00m\n\u001b[0;32m     87\u001b[0m pix_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgba\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_mask \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb24\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader \u001b[38;5;241m=\u001b[39m \u001b[43mFFMPEG_VideoReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpix_fmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpix_fmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtarget_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mresize_algo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresize_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfps_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Make some of the reader's attributes accessible from the clip\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mduration\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:35\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.__init__\u001b[1;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m infos \u001b[38;5;241m=\u001b[39m \u001b[43mffmpeg_parse_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_duration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mfps_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps \u001b[38;5;241m=\u001b[39m infos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_fps\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m infos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mD:\\venv\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:270\u001b[0m, in \u001b[0;36mffmpeg_parse_infos\u001b[1;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[0;32m    268\u001b[0m lines \u001b[38;5;241m=\u001b[39m infos\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m lines[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoviePy error: the file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m could not be found!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check that you entered the correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    272\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m%\u001b[39mfilename)\n\u001b[0;32m    274\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# get duration (in seconds)\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: MoviePy error: the file output_video_part_0\\result.mp4 could not be found!\nPlease check that you entered the correct path."
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "text = \"Я очень счастлив сегодня! Но вчера мне было грустно. Завтра будет новый день, и я надеюсь, что он будет лучше.\"\n",
    "\n",
    "Make_avatar(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3_8_neural_networks",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05c710f759a244ba9b19fec4d6911632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1585232a2cc0468bab6c25dd732d000c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b0bfd95befd4009800fdc0718e227db",
       "IPY_MODEL_a4568efecb054f1aa6bbd62e8ed4471f",
       "IPY_MODEL_86bde030395f447199944095d4149b16"
      ],
      "layout": "IPY_MODEL_5e3ced642e764c78b3e5edb3757598ed"
     }
    },
    "19b87590c4e94419b2cdca4aa6dd0dbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24cab206b88d444e92da0b4ce5b486be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c30de3648bd484cbadf444250eae7be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b8f0d689130419ea4e4e8c726e7433a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e3ced642e764c78b3e5edb3757598ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "690650a936a14fdba144151a1dcb9df7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73fab7e20aa240f1b0e42d3661df5734": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24cab206b88d444e92da0b4ce5b486be",
      "max": 5812,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76f7ce8e599a468a8ee0d887f0ae15b4",
      "value": 5812
     }
    },
    "76f7ce8e599a468a8ee0d887f0ae15b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79db326166db46a09ff85dc8a2a432a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb8aacd4797b4df79e17ab2953a7ebcc",
      "placeholder": "​",
      "style": "IPY_MODEL_992c01ff6726432181a0ee0c6093e8f3",
      "value": "Map: 100%"
     }
    },
    "8430ce4307064df0b4c72b4f41c8c5ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86bde030395f447199944095d4149b16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df24c9bbf25a47549691fdfb0907ac5e",
      "placeholder": "​",
      "style": "IPY_MODEL_d9571c9f10d3425f9681dc657ea82273",
      "value": " 5812/5812 [00:00&lt;00:00, 34439.14 examples/s]"
     }
    },
    "9581083cabd64fa7b61e65e4e49f5098": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79db326166db46a09ff85dc8a2a432a8",
       "IPY_MODEL_73fab7e20aa240f1b0e42d3661df5734",
       "IPY_MODEL_d5213b68296f440bb0d06b645631c24a"
      ],
      "layout": "IPY_MODEL_8430ce4307064df0b4c72b4f41c8c5ab"
     }
    },
    "992c01ff6726432181a0ee0c6093e8f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b0bfd95befd4009800fdc0718e227db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_690650a936a14fdba144151a1dcb9df7",
      "placeholder": "​",
      "style": "IPY_MODEL_9e66884d200d49fabaf365b06cf3150e",
      "value": "Map: 100%"
     }
    },
    "9e66884d200d49fabaf365b06cf3150e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4568efecb054f1aa6bbd62e8ed4471f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b8f0d689130419ea4e4e8c726e7433a",
      "max": 5812,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_19b87590c4e94419b2cdca4aa6dd0dbd",
      "value": 5812
     }
    },
    "d5213b68296f440bb0d06b645631c24a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c30de3648bd484cbadf444250eae7be",
      "placeholder": "​",
      "style": "IPY_MODEL_05c710f759a244ba9b19fec4d6911632",
      "value": " 5812/5812 [00:14&lt;00:00, 389.83 examples/s]"
     }
    },
    "d9571c9f10d3425f9681dc657ea82273": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df24c9bbf25a47549691fdfb0907ac5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb8aacd4797b4df79e17ab2953a7ebcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
